Training on device: cuda
Step 10: train_loss=9.1605, val_loss=nan, ppl=nan, lr=7.20e-05
Step 20: train_loss=8.8219, val_loss=nan, ppl=nan, lr=1.52e-04
Step 30: train_loss=7.4153, val_loss=nan, ppl=nan, lr=2.32e-04
Step 40: train_loss=6.2552, val_loss=nan, ppl=nan, lr=3.12e-04
Step 50: train_loss=5.7878, val_loss=5.7656, ppl=326.31, lr=3.92e-04
Step 60: train_loss=5.5116, val_loss=nan, ppl=nan, lr=4.72e-04
Step 70: train_loss=5.1077, val_loss=nan, ppl=nan, lr=5.52e-04
Step 80: train_loss=4.8046, val_loss=nan, ppl=nan, lr=6.32e-04
Step 90: train_loss=4.4874, val_loss=nan, ppl=nan, lr=7.12e-04
Step 100: train_loss=4.1627, val_loss=4.1572, ppl=64.24, lr=7.92e-04
Step 110: train_loss=3.9474, val_loss=nan, ppl=nan, lr=8.72e-04
Step 120: train_loss=3.8070, val_loss=nan, ppl=nan, lr=9.52e-04
Step 130: train_loss=3.6594, val_loss=nan, ppl=nan, lr=1.00e-03
Step 140: train_loss=3.5570, val_loss=nan, ppl=nan, lr=1.00e-03
Step 150: train_loss=3.4264, val_loss=3.4142, ppl=30.77, lr=1.00e-03
Step 160: train_loss=3.2821, val_loss=nan, ppl=nan, lr=9.99e-04
Step 170: train_loss=3.2411, val_loss=nan, ppl=nan, lr=9.99e-04
Step 180: train_loss=3.1790, val_loss=nan, ppl=nan, lr=9.98e-04
Step 190: train_loss=3.0809, val_loss=nan, ppl=nan, lr=9.97e-04
Step 200: train_loss=2.9743, val_loss=2.9807, ppl=19.58, lr=9.96e-04
Step 210: train_loss=2.8857, val_loss=nan, ppl=nan, lr=9.95e-04
Step 220: train_loss=2.8413, val_loss=nan, ppl=nan, lr=9.94e-04
Step 230: train_loss=2.8091, val_loss=nan, ppl=nan, lr=9.93e-04
Step 240: train_loss=2.6938, val_loss=nan, ppl=nan, lr=9.91e-04
Step 250: train_loss=2.6623, val_loss=2.6551, ppl=14.33, lr=9.89e-04
Step 260: train_loss=2.6491, val_loss=nan, ppl=nan, lr=9.88e-04
Step 270: train_loss=2.6069, val_loss=nan, ppl=nan, lr=9.86e-04
Step 280: train_loss=2.5353, val_loss=nan, ppl=nan, lr=9.84e-04
Step 290: train_loss=2.4440, val_loss=nan, ppl=nan, lr=9.81e-04
Step 300: train_loss=2.4619, val_loss=2.4506, ppl=11.73, lr=9.79e-04
Step 310: train_loss=2.4168, val_loss=nan, ppl=nan, lr=9.77e-04
Step 320: train_loss=2.3957, val_loss=nan, ppl=nan, lr=9.74e-04
Step 330: train_loss=2.3609, val_loss=nan, ppl=nan, lr=9.71e-04
Step 340: train_loss=2.3458, val_loss=nan, ppl=nan, lr=9.69e-04
Step 350: train_loss=2.2635, val_loss=2.2834, ppl=9.62, lr=9.66e-04
Step 360: train_loss=2.2504, val_loss=nan, ppl=nan, lr=9.62e-04
Step 370: train_loss=2.2385, val_loss=nan, ppl=nan, lr=9.59e-04
Step 380: train_loss=2.2076, val_loss=nan, ppl=nan, lr=9.56e-04
Step 390: train_loss=2.2075, val_loss=nan, ppl=nan, lr=9.52e-04
Step 400: train_loss=2.1426, val_loss=2.1608, ppl=8.52, lr=9.49e-04
Step 410: train_loss=2.1225, val_loss=nan, ppl=nan, lr=9.45e-04
Step 420: train_loss=2.1222, val_loss=nan, ppl=nan, lr=9.41e-04
Step 430: train_loss=2.0959, val_loss=nan, ppl=nan, lr=9.37e-04
Step 440: train_loss=2.0957, val_loss=nan, ppl=nan, lr=9.33e-04
Step 450: train_loss=2.0701, val_loss=2.0653, ppl=7.93, lr=9.29e-04
Step 460: train_loss=2.0388, val_loss=nan, ppl=nan, lr=9.24e-04
Step 470: train_loss=2.0335, val_loss=nan, ppl=nan, lr=9.20e-04
Step 480: train_loss=2.0133, val_loss=nan, ppl=nan, lr=9.15e-04
Step 490: train_loss=2.0352, val_loss=nan, ppl=nan, lr=9.11e-04
Step 500: train_loss=1.9725, val_loss=1.9769, ppl=7.19, lr=9.06e-04
Saved checkpoint at iter 500
Step 510: train_loss=1.9508, val_loss=nan, ppl=nan, lr=9.01e-04
Step 520: train_loss=1.9938, val_loss=nan, ppl=nan, lr=8.96e-04
Step 530: train_loss=1.9497, val_loss=nan, ppl=nan, lr=8.91e-04
Step 540: train_loss=1.9457, val_loss=nan, ppl=nan, lr=8.86e-04
Step 550: train_loss=1.9463, val_loss=1.9195, ppl=7.00, lr=8.80e-04
Step 560: train_loss=1.8932, val_loss=nan, ppl=nan, lr=8.75e-04
Step 570: train_loss=1.8875, val_loss=nan, ppl=nan, lr=8.69e-04
Step 580: train_loss=1.8957, val_loss=nan, ppl=nan, lr=8.64e-04
Step 590: train_loss=1.9007, val_loss=nan, ppl=nan, lr=8.58e-04
Step 600: train_loss=1.8648, val_loss=1.8693, ppl=6.45, lr=8.52e-04
Step 610: train_loss=1.8671, val_loss=nan, ppl=nan, lr=8.46e-04
Step 620: train_loss=1.8770, val_loss=nan, ppl=nan, lr=8.40e-04
Step 630: train_loss=1.8427, val_loss=nan, ppl=nan, lr=8.34e-04
Step 640: train_loss=1.8194, val_loss=nan, ppl=nan, lr=8.28e-04
Step 650: train_loss=1.8292, val_loss=1.8250, ppl=6.23, lr=8.21e-04
Step 660: train_loss=1.7966, val_loss=nan, ppl=nan, lr=8.15e-04
Step 670: train_loss=1.8226, val_loss=nan, ppl=nan, lr=8.08e-04
Step 680: train_loss=1.8159, val_loss=nan, ppl=nan, lr=8.02e-04
Step 690: train_loss=1.8059, val_loss=nan, ppl=nan, lr=7.95e-04
Step 700: train_loss=1.7892, val_loss=1.7916, ppl=5.98, lr=7.88e-04
Step 710: train_loss=1.7826, val_loss=nan, ppl=nan, lr=7.81e-04
Step 720: train_loss=1.7898, val_loss=nan, ppl=nan, lr=7.74e-04
Step 730: train_loss=1.7764, val_loss=nan, ppl=nan, lr=7.67e-04
Step 740: train_loss=1.7844, val_loss=nan, ppl=nan, lr=7.60e-04
Step 750: train_loss=1.7630, val_loss=1.7599, ppl=5.83, lr=7.53e-04
Step 760: train_loss=1.7591, val_loss=nan, ppl=nan, lr=7.46e-04
Step 770: train_loss=1.7297, val_loss=nan, ppl=nan, lr=7.39e-04
Step 780: train_loss=1.7422, val_loss=nan, ppl=nan, lr=7.31e-04
Step 790: train_loss=1.7356, val_loss=nan, ppl=nan, lr=7.24e-04
Step 800: train_loss=1.7400, val_loss=1.7397, ppl=5.70, lr=7.17e-04
Step 810: train_loss=1.7311, val_loss=nan, ppl=nan, lr=7.09e-04
Step 820: train_loss=1.7296, val_loss=nan, ppl=nan, lr=7.01e-04
Step 830: train_loss=1.6916, val_loss=nan, ppl=nan, lr=6.94e-04
Step 840: train_loss=1.7145, val_loss=nan, ppl=nan, lr=6.86e-04
Step 850: train_loss=1.7145, val_loss=1.7125, ppl=5.55, lr=6.78e-04
Step 860: train_loss=1.6776, val_loss=nan, ppl=nan, lr=6.71e-04
Step 870: train_loss=1.6669, val_loss=nan, ppl=nan, lr=6.63e-04
Step 880: train_loss=1.6583, val_loss=nan, ppl=nan, lr=6.55e-04
Step 890: train_loss=1.6674, val_loss=nan, ppl=nan, lr=6.47e-04
Step 900: train_loss=1.6891, val_loss=1.6876, ppl=5.41, lr=6.39e-04
Step 910: train_loss=1.6941, val_loss=nan, ppl=nan, lr=6.31e-04
Step 920: train_loss=1.6805, val_loss=nan, ppl=nan, lr=6.23e-04
Step 930: train_loss=1.6849, val_loss=nan, ppl=nan, lr=6.15e-04
Step 940: train_loss=1.6717, val_loss=nan, ppl=nan, lr=6.07e-04
Step 950: train_loss=1.6717, val_loss=1.6703, ppl=5.32, lr=5.99e-04
Step 960: train_loss=1.6690, val_loss=nan, ppl=nan, lr=5.90e-04
Step 970: train_loss=1.6801, val_loss=nan, ppl=nan, lr=5.82e-04
Step 980: train_loss=1.6568, val_loss=nan, ppl=nan, lr=5.74e-04
Step 990: train_loss=1.6386, val_loss=nan, ppl=nan, lr=5.66e-04
Step 1000: train_loss=1.6596, val_loss=1.6505, ppl=5.26, lr=5.58e-04
Saved checkpoint at iter 1000
Step 1010: train_loss=1.6840, val_loss=nan, ppl=nan, lr=5.49e-04
Step 1020: train_loss=1.6305, val_loss=nan, ppl=nan, lr=5.41e-04
Step 1030: train_loss=1.6413, val_loss=nan, ppl=nan, lr=5.33e-04
Step 1040: train_loss=1.6386, val_loss=nan, ppl=nan, lr=5.24e-04
Step 1050: train_loss=1.6199, val_loss=1.6359, ppl=5.05, lr=5.16e-04
Step 1060: train_loss=1.6729, val_loss=nan, ppl=nan, lr=5.08e-04
Step 1070: train_loss=1.6484, val_loss=nan, ppl=nan, lr=5.00e-04
Step 1080: train_loss=1.6314, val_loss=nan, ppl=nan, lr=4.91e-04
Step 1090: train_loss=1.6349, val_loss=nan, ppl=nan, lr=4.83e-04
Step 1100: train_loss=1.6286, val_loss=1.6232, ppl=5.10, lr=4.75e-04
Step 1110: train_loss=1.6066, val_loss=nan, ppl=nan, lr=4.66e-04
Step 1120: train_loss=1.6257, val_loss=nan, ppl=nan, lr=4.58e-04
Step 1130: train_loss=1.6141, val_loss=nan, ppl=nan, lr=4.50e-04
Step 1140: train_loss=1.5930, val_loss=nan, ppl=nan, lr=4.42e-04
Step 1150: train_loss=1.5960, val_loss=1.6103, ppl=4.93, lr=4.34e-04
Step 1160: train_loss=1.5890, val_loss=nan, ppl=nan, lr=4.25e-04
Step 1170: train_loss=1.5865, val_loss=nan, ppl=nan, lr=4.17e-04
Step 1180: train_loss=1.6153, val_loss=nan, ppl=nan, lr=4.09e-04
Step 1190: train_loss=1.6122, val_loss=nan, ppl=nan, lr=4.01e-04
Step 1200: train_loss=1.6036, val_loss=1.5990, ppl=4.97, lr=3.93e-04
Step 1210: train_loss=1.6079, val_loss=nan, ppl=nan, lr=3.85e-04
Step 1220: train_loss=1.5786, val_loss=nan, ppl=nan, lr=3.77e-04
Step 1230: train_loss=1.6035, val_loss=nan, ppl=nan, lr=3.69e-04
Step 1240: train_loss=1.5797, val_loss=nan, ppl=nan, lr=3.61e-04
Step 1250: train_loss=1.5609, val_loss=1.5920, ppl=4.76, lr=3.53e-04
Step 1260: train_loss=1.5520, val_loss=nan, ppl=nan, lr=3.45e-04
Step 1270: train_loss=1.5716, val_loss=nan, ppl=nan, lr=3.37e-04
Step 1280: train_loss=1.5682, val_loss=nan, ppl=nan, lr=3.29e-04
Step 1290: train_loss=1.5751, val_loss=nan, ppl=nan, lr=3.22e-04
Step 1300: train_loss=1.5613, val_loss=1.5717, ppl=4.76, lr=3.14e-04
Step 1310: train_loss=1.5964, val_loss=nan, ppl=nan, lr=3.06e-04
Step 1320: train_loss=1.5853, val_loss=nan, ppl=nan, lr=2.99e-04
Step 1330: train_loss=1.5689, val_loss=nan, ppl=nan, lr=2.91e-04
Step 1340: train_loss=1.5637, val_loss=nan, ppl=nan, lr=2.84e-04
Step 1350: train_loss=1.5797, val_loss=1.5666, ppl=4.85, lr=2.76e-04
Step 1360: train_loss=1.5721, val_loss=nan, ppl=nan, lr=2.69e-04
Step 1370: train_loss=1.5590, val_loss=nan, ppl=nan, lr=2.62e-04
Step 1380: train_loss=1.5646, val_loss=nan, ppl=nan, lr=2.55e-04
Step 1390: train_loss=1.5642, val_loss=nan, ppl=nan, lr=2.48e-04
Step 1400: train_loss=1.5627, val_loss=1.5604, ppl=4.77, lr=2.40e-04
Step 1410: train_loss=1.5362, val_loss=nan, ppl=nan, lr=2.33e-04
Step 1420: train_loss=1.5364, val_loss=nan, ppl=nan, lr=2.27e-04
Step 1430: train_loss=1.5381, val_loss=nan, ppl=nan, lr=2.20e-04
Step 1440: train_loss=1.5251, val_loss=nan, ppl=nan, lr=2.13e-04
Step 1450: train_loss=1.5453, val_loss=1.5538, ppl=4.69, lr=2.06e-04
Step 1460: train_loss=1.5570, val_loss=nan, ppl=nan, lr=2.00e-04
Step 1470: train_loss=1.5484, val_loss=nan, ppl=nan, lr=1.93e-04
Step 1480: train_loss=1.5565, val_loss=nan, ppl=nan, lr=1.87e-04
Step 1490: train_loss=1.5202, val_loss=nan, ppl=nan, lr=1.81e-04
Step 1500: train_loss=1.5443, val_loss=1.5424, ppl=4.68, lr=1.74e-04
Saved checkpoint at iter 1500
Step 1510: train_loss=1.5403, val_loss=nan, ppl=nan, lr=1.68e-04
Step 1520: train_loss=1.5421, val_loss=nan, ppl=nan, lr=1.62e-04
Step 1530: train_loss=1.5455, val_loss=nan, ppl=nan, lr=1.56e-04
Step 1540: train_loss=1.5459, val_loss=nan, ppl=nan, lr=1.50e-04
Step 1550: train_loss=1.5397, val_loss=1.5369, ppl=4.66, lr=1.45e-04
Step 1560: train_loss=1.5604, val_loss=nan, ppl=nan, lr=1.39e-04
Step 1570: train_loss=1.5259, val_loss=nan, ppl=nan, lr=1.34e-04
Step 1580: train_loss=1.5448, val_loss=nan, ppl=nan, lr=1.28e-04
Step 1590: train_loss=1.5279, val_loss=nan, ppl=nan, lr=1.23e-04
Step 1600: train_loss=1.5157, val_loss=1.5341, ppl=4.55, lr=1.18e-04
Step 1610: train_loss=1.5150, val_loss=nan, ppl=nan, lr=1.12e-04
Step 1620: train_loss=1.5400, val_loss=nan, ppl=nan, lr=1.07e-04
Step 1630: train_loss=1.5126, val_loss=nan, ppl=nan, lr=1.03e-04
Step 1640: train_loss=1.5586, val_loss=nan, ppl=nan, lr=9.78e-05
Step 1650: train_loss=1.5104, val_loss=1.5295, ppl=4.53, lr=9.32e-05
Step 1660: train_loss=1.4995, val_loss=nan, ppl=nan, lr=8.86e-05
Step 1670: train_loss=1.5299, val_loss=nan, ppl=nan, lr=8.42e-05
Step 1680: train_loss=1.5414, val_loss=nan, ppl=nan, lr=7.99e-05
Step 1690: train_loss=1.5359, val_loss=nan, ppl=nan, lr=7.57e-05
Step 1700: train_loss=1.5104, val_loss=1.5250, ppl=4.53, lr=7.16e-05
Step 1710: train_loss=1.4967, val_loss=nan, ppl=nan, lr=6.77e-05
Step 1720: train_loss=1.5529, val_loss=nan, ppl=nan, lr=6.39e-05
Step 1730: train_loss=1.4997, val_loss=nan, ppl=nan, lr=6.02e-05
Step 1740: train_loss=1.5229, val_loss=nan, ppl=nan, lr=5.66e-05
Step 1750: train_loss=1.5167, val_loss=1.5211, ppl=4.56, lr=5.31e-05
Step 1760: train_loss=1.5137, val_loss=nan, ppl=nan, lr=4.98e-05
Step 1770: train_loss=1.5241, val_loss=nan, ppl=nan, lr=4.66e-05
Step 1780: train_loss=1.5225, val_loss=nan, ppl=nan, lr=4.35e-05
Step 1790: train_loss=1.5199, val_loss=nan, ppl=nan, lr=4.06e-05
Step 1800: train_loss=1.5252, val_loss=1.5223, ppl=4.60, lr=3.78e-05
Step 1810: train_loss=1.5065, val_loss=nan, ppl=nan, lr=3.51e-05
Step 1820: train_loss=1.5459, val_loss=nan, ppl=nan, lr=3.26e-05
Step 1830: train_loss=1.5107, val_loss=nan, ppl=nan, lr=3.02e-05
Step 1840: train_loss=1.5043, val_loss=nan, ppl=nan, lr=2.79e-05
Step 1850: train_loss=1.5023, val_loss=1.5172, ppl=4.49, lr=2.58e-05
Step 1860: train_loss=1.5163, val_loss=nan, ppl=nan, lr=2.37e-05
Step 1870: train_loss=1.5068, val_loss=nan, ppl=nan, lr=2.19e-05
Step 1880: train_loss=1.4829, val_loss=nan, ppl=nan, lr=2.01e-05
Step 1890: train_loss=1.4966, val_loss=nan, ppl=nan, lr=1.85e-05
Step 1900: train_loss=1.5393, val_loss=1.5183, ppl=4.66, lr=1.71e-05
Step 1910: train_loss=1.4897, val_loss=nan, ppl=nan, lr=1.57e-05
Step 1920: train_loss=1.4910, val_loss=nan, ppl=nan, lr=1.46e-05
Step 1930: train_loss=1.4929, val_loss=nan, ppl=nan, lr=1.35e-05
Step 1940: train_loss=1.5044, val_loss=nan, ppl=nan, lr=1.26e-05
Step 1950: train_loss=1.5187, val_loss=1.5161, ppl=4.57, lr=1.18e-05
Step 1960: train_loss=1.4977, val_loss=nan, ppl=nan, lr=1.12e-05
Step 1970: train_loss=1.5087, val_loss=nan, ppl=nan, lr=1.07e-05
Step 1980: train_loss=1.5186, val_loss=nan, ppl=nan, lr=1.03e-05
Step 1990: train_loss=1.4806, val_loss=nan, ppl=nan, lr=1.01e-05
Step 2000: train_loss=1.5202, val_loss=1.5146, ppl=4.57, lr=1.00e-05
Saved checkpoint at iter 2000
Step 2010: train_loss=1.5065, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2020: train_loss=1.5351, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2030: train_loss=1.5214, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2040: train_loss=1.5195, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2050: train_loss=1.5393, val_loss=1.5177, ppl=4.66, lr=1.00e-05
Step 2060: train_loss=1.4932, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2070: train_loss=1.5243, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2080: train_loss=1.5147, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2090: train_loss=1.5367, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2100: train_loss=1.4885, val_loss=1.5115, ppl=4.43, lr=1.00e-05
Step 2110: train_loss=1.5214, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2120: train_loss=1.5040, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2130: train_loss=1.5340, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2140: train_loss=1.5266, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2150: train_loss=1.5162, val_loss=1.5144, ppl=4.55, lr=1.00e-05
Step 2160: train_loss=1.5126, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2170: train_loss=1.4975, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2180: train_loss=1.5096, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2190: train_loss=1.4942, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2200: train_loss=1.5045, val_loss=1.5157, ppl=4.50, lr=1.00e-05
Step 2210: train_loss=1.5049, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2220: train_loss=1.4844, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2230: train_loss=1.5031, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2240: train_loss=1.5273, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2250: train_loss=1.5381, val_loss=1.5111, ppl=4.66, lr=1.00e-05
Step 2260: train_loss=1.4844, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2270: train_loss=1.5146, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2280: train_loss=1.5090, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2290: train_loss=1.4845, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2300: train_loss=1.5189, val_loss=1.5145, ppl=4.57, lr=1.00e-05
Step 2310: train_loss=1.4776, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2320: train_loss=1.5305, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2330: train_loss=1.5076, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2340: train_loss=1.5135, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2350: train_loss=1.5332, val_loss=1.5115, ppl=4.63, lr=1.00e-05
Step 2360: train_loss=1.5085, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2370: train_loss=1.5125, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2380: train_loss=1.5095, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2390: train_loss=1.5052, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2400: train_loss=1.5189, val_loss=1.5146, ppl=4.57, lr=1.00e-05
Step 2410: train_loss=1.5158, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2420: train_loss=1.4967, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2430: train_loss=1.5238, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2440: train_loss=1.5188, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2450: train_loss=1.5241, val_loss=1.5087, ppl=4.59, lr=1.00e-05
Step 2460: train_loss=1.5118, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2470: train_loss=1.5387, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2480: train_loss=1.5283, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2490: train_loss=1.5038, val_loss=nan, ppl=nan, lr=1.00e-05
Step 2500: train_loss=1.5124, val_loss=1.5117, ppl=4.54, lr=1.00e-05
Saved checkpoint at iter 2500
Training complete at step 2500
